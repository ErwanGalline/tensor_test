
##########################################
## Speech CCN model comparison
## 12/10/2017
## TF 1.3 , build form source , OpenCL optim , no gpu

##########################################
## Model-1 :
- 1 Conv layer + 3 fully connected layers
- filter size : [4,16] 
- No batch normalization
- 0.6 < dropout < 0.9
- trained until 21k iteration
- training step size : 100
- 0.005 > training rate > 0.0005 
- accuracy > 93% (training)
- perf : ~1sec/train. step
- generalisation : bad 


##########################################
## Model-2 :
- 2 Conv layers + 3 fully connected layers
- filter size : [4,16] (both)
- ahs batch normalization after conv layers
- dropout >= 0.9
- tainig step size : 100
- training rate : 0.01
- perf : : ~1.5sec/train. step
